# Goal
透過MOT(Multiple Object Tracking)方式將淡江門口行人路線進行追蹤，（後續可以多拍攝幾個點位，進行比較）並將結果進行統計、視覺化，後續可以研究不同時段，學生路徑動向或是人流密集區域劃分。大致如下圖，不過是將車換成人（這部分在辨識上難度更高），完成行人動向追蹤後，再將結果投影回地圖或是空曠的同樣場景（作為底圖），已完成視覺化。
同時由於MOT算法會用到物件辨識的模型以及追蹤算法，可以比較不同模型架構和這個實際MOT表現，並分析表現好壞原因，最後找出最適合的模型架構（考量速度和準確率），作為最後所使用辨識模型。最後將其部署於Jetson Orin Nano等邊緣計算設備，或是網站。

![[images/Pasted image 20240304063534.png]]
### Data

#### Training (Optional)
透過VisDrone等等資料集，重新訓練模型，使其能夠更明確辨認出行人
#### Validating
**基本：** 從（商管七樓樓梯外部）向煙橋、文學院、紅27進行拍攝，拍攝近5分鐘行人流向
**延伸：** 多時段 >> 進行比較，拍攝15分鐘完整影片做為最後測試資料

**Note:** 需在畫面中確定好數個參照物，以保持拍攝角度畫面一致，且後續可以根據參照物將行人動向預測投影至Google Map

### Model Comparison

使用不同物件辨識模型和修改模型架構等等，並比較結果。
Yolo, Faster R-CNN, DETR, RE-DETR
### Visualization

#### 動向
根據追蹤結果畫分出個行人動向

#### 人群
根據停留時間或是行人距離去找出是否有人群

#### 統計結果
統計各方向人數

### GUI / Website
#### 1. 影片上傳
使用者可以上傳影片，並同步將結果呈現於GUI/Website上，若是固定地點得圖片，可以將結果投影回底圖，例如使用者可以選擇所拍攝地點（商管外、．．． 等等其他有底圖地點），則會投影至相應底圖。
#### 2. 鏡頭實時追蹤

#### Problem
1. 由於MOT需要更大的計算量，要維持一定禎數以及準確率下，需要足夠計算資源，Jetson Orin Nano上直接做計算可能無法達到即時追蹤的效果，因此可能需要Cloud Computing的方式，將畫面透過伺服器做計算，再回傳至GUI或網站，已達到實時預測，不過中間會有一定延遲需要考量
### Future Work

#### 1. MultiModel - Audio & Object Tracking (不確定)
透過結合聲音的多模態對於後續行人流向和密集程度進行預測，在聲音上可以先嘗試用基本的聲音大小，後續在透過不同模型，尋找特定Pattern，並透過多模態和原先Object Tracking做結合，進行預測

---
# Presentation

### Mid-Term
完成基本追蹤模型和影片上傳介面
#### 報告內容
1. 動機
2. 系統流程
3. 文獻探討
	1. MOT流程
	2. Object Detection 模型
	3. 追蹤算法
4. 目前成果展示 
### Final-Term
比較不同模型架構，完成完整模型和實時追蹤介面
#### 報告內容
1. 系統架構回顧
2. 模型比較結果
3. 視覺化結果 （分析）
4. 最終成果展示
5. 未來展望
---
# Schedule
